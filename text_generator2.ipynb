{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3.6 (tensorflow)",
      "language": "python",
      "name": "tensorflow"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "text_generator2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRJq5tjRdNah"
      },
      "source": [
        "from tensorflow.keras.callbacks import LambdaCallback\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.utils import get_file\n",
        "from string import punctuation\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import sys\n",
        "import io\n",
        "import requests\n",
        "import re"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "HGthjJAKdXLY",
        "outputId": "3ff194ca-1161-4e85-f4a3-d5c855751b0c"
      },
      "source": [
        "features = pd.read_csv(\"final_df2.csv\")\n",
        "features.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>movie</th>\n",
              "      <th>release date</th>\n",
              "      <th>rating</th>\n",
              "      <th>genre</th>\n",
              "      <th>language</th>\n",
              "      <th>directors</th>\n",
              "      <th>duration</th>\n",
              "      <th>Box Office</th>\n",
              "      <th>Description</th>\n",
              "      <th>Audience Score</th>\n",
              "      <th>Tomatometer</th>\n",
              "      <th>Reviews</th>\n",
              "      <th>compound_audience</th>\n",
              "      <th>neutral_audience</th>\n",
              "      <th>positive_audience</th>\n",
              "      <th>negative_audience</th>\n",
              "      <th>positive</th>\n",
              "      <th>negative</th>\n",
              "      <th>neutral</th>\n",
              "      <th>compound</th>\n",
              "      <th>aud_asp_neutral</th>\n",
              "      <th>aud_asp_negative</th>\n",
              "      <th>aud_asp_positive</th>\n",
              "      <th>critic_reviews</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>chicken_run</td>\n",
              "      <td>Jun 21, 2000</td>\n",
              "      <td>G</td>\n",
              "      <td>['animation', 'kids and family', 'comedy', 'ad...</td>\n",
              "      <td>English</td>\n",
              "      <td>['Peter Lord']</td>\n",
              "      <td>1h 25m</td>\n",
              "      <td>NaN</td>\n",
              "      <td>This engaging stop-motion, claymation adventur...</td>\n",
              "      <td>65.0</td>\n",
              "      <td>97.0</td>\n",
              "      <td>['While Chicken Run has a great animation styl...</td>\n",
              "      <td>0.395363</td>\n",
              "      <td>0.764375</td>\n",
              "      <td>0.208500</td>\n",
              "      <td>0.027125</td>\n",
              "      <td>0.14000</td>\n",
              "      <td>0.0675</td>\n",
              "      <td>0.79250</td>\n",
              "      <td>0.130605</td>\n",
              "      <td>0.127229</td>\n",
              "      <td>0.261164</td>\n",
              "      <td>0.611607</td>\n",
              "      <td>Chicken Run, if anything, offers an alternativ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>the_taste_of_others</td>\n",
              "      <td>Feb 26, 2002</td>\n",
              "      <td>R</td>\n",
              "      <td>['comedy']</td>\n",
              "      <td>French (France)</td>\n",
              "      <td>['Agn√®s Jaoui']</td>\n",
              "      <td>1h 52m</td>\n",
              "      <td>$635.3K</td>\n",
              "      <td>Castella (Jean-Pierre Bacri) is a successful b...</td>\n",
              "      <td>82.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>['A nice comedy that has pokes some friendly b...</td>\n",
              "      <td>0.544600</td>\n",
              "      <td>0.700125</td>\n",
              "      <td>0.237250</td>\n",
              "      <td>0.062625</td>\n",
              "      <td>0.25505</td>\n",
              "      <td>0.0301</td>\n",
              "      <td>0.71490</td>\n",
              "      <td>0.400550</td>\n",
              "      <td>0.044488</td>\n",
              "      <td>0.232734</td>\n",
              "      <td>0.722778</td>\n",
              "      <td>Succeeds with believable characters and situat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>yi_yi</td>\n",
              "      <td>May 8, 2001</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['drama']</td>\n",
              "      <td>Edward Yang</td>\n",
              "      <td>['Edward Yang']</td>\n",
              "      <td>2h 53m</td>\n",
              "      <td>$969.1K</td>\n",
              "      <td>Set in Taiwan, the film follows the lives of t...</td>\n",
              "      <td>91.0</td>\n",
              "      <td>97.0</td>\n",
              "      <td>['A city symphony in minor key with a city-siz...</td>\n",
              "      <td>0.559800</td>\n",
              "      <td>0.806111</td>\n",
              "      <td>0.152556</td>\n",
              "      <td>0.041444</td>\n",
              "      <td>0.20600</td>\n",
              "      <td>0.0403</td>\n",
              "      <td>0.75370</td>\n",
              "      <td>0.348930</td>\n",
              "      <td>0.169338</td>\n",
              "      <td>0.233988</td>\n",
              "      <td>0.596674</td>\n",
              "      <td>I felt like I had lived it, and not just becau...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>memento</td>\n",
              "      <td>Mar 1, 2017</td>\n",
              "      <td>R (Language|Drug Content|Violence)</td>\n",
              "      <td>['mystery and thriller']</td>\n",
              "      <td>English</td>\n",
              "      <td>['Christopher Nolan']</td>\n",
              "      <td>1h 56m</td>\n",
              "      <td>$25.5M</td>\n",
              "      <td>Leonard (Guy Pearce) is tracking down the man ...</td>\n",
              "      <td>94.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>['Not a masterpiece but really good', \"Memento...</td>\n",
              "      <td>0.326714</td>\n",
              "      <td>0.740143</td>\n",
              "      <td>0.205429</td>\n",
              "      <td>0.054571</td>\n",
              "      <td>0.10860</td>\n",
              "      <td>0.0562</td>\n",
              "      <td>0.83515</td>\n",
              "      <td>0.157130</td>\n",
              "      <td>0.204062</td>\n",
              "      <td>0.217740</td>\n",
              "      <td>0.578198</td>\n",
              "      <td>Think of all the ways that a linear film struc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>the_life_and_times_of_hank_greenberg</td>\n",
              "      <td>Jul 2, 1999</td>\n",
              "      <td>PG (Mild Language|Thematic Elements)</td>\n",
              "      <td>['biography', 'documentary']</td>\n",
              "      <td>English</td>\n",
              "      <td>['Aviva Kempner']</td>\n",
              "      <td>1h 29m</td>\n",
              "      <td>$1.7M</td>\n",
              "      <td>\"The Life and Times of Hank Greenberg\" is a hu...</td>\n",
              "      <td>80.0</td>\n",
              "      <td>97.0</td>\n",
              "      <td>[\"Dedicated to the millions of Detroit Tigers ...</td>\n",
              "      <td>0.840233</td>\n",
              "      <td>0.697333</td>\n",
              "      <td>0.289333</td>\n",
              "      <td>0.013333</td>\n",
              "      <td>0.22375</td>\n",
              "      <td>0.0243</td>\n",
              "      <td>0.75195</td>\n",
              "      <td>0.574785</td>\n",
              "      <td>0.047392</td>\n",
              "      <td>0.034910</td>\n",
              "      <td>0.917698</td>\n",
              "      <td>It's an adroit manipulation of interviews and ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                     critic_reviews\n",
              "0           0  ...  Chicken Run, if anything, offers an alternativ...\n",
              "1           1  ...  Succeeds with believable characters and situat...\n",
              "2           2  ...  I felt like I had lived it, and not just becau...\n",
              "3           3  ...  Think of all the ways that a linear film struc...\n",
              "4           4  ...  It's an adroit manipulation of interviews and ...\n",
              "\n",
              "[5 rows x 25 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "lctRqb1adfcK",
        "outputId": "9e3a6389-f76c-415b-e36f-455e3751b8cf"
      },
      "source": [
        "genre=\"documentary\"\n",
        "features=features.dropna(subset=[\"genre\"])\n",
        "selected_genre=features[features[\"genre\"].str.contains(genre)]\n",
        "selected_genre.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>movie</th>\n",
              "      <th>release date</th>\n",
              "      <th>rating</th>\n",
              "      <th>genre</th>\n",
              "      <th>language</th>\n",
              "      <th>directors</th>\n",
              "      <th>duration</th>\n",
              "      <th>Box Office</th>\n",
              "      <th>Description</th>\n",
              "      <th>Audience Score</th>\n",
              "      <th>Tomatometer</th>\n",
              "      <th>Reviews</th>\n",
              "      <th>compound_audience</th>\n",
              "      <th>neutral_audience</th>\n",
              "      <th>positive_audience</th>\n",
              "      <th>negative_audience</th>\n",
              "      <th>positive</th>\n",
              "      <th>negative</th>\n",
              "      <th>neutral</th>\n",
              "      <th>compound</th>\n",
              "      <th>aud_asp_neutral</th>\n",
              "      <th>aud_asp_negative</th>\n",
              "      <th>aud_asp_positive</th>\n",
              "      <th>critic_reviews</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>the_life_and_times_of_hank_greenberg</td>\n",
              "      <td>Jul 2, 1999</td>\n",
              "      <td>PG (Mild Language|Thematic Elements)</td>\n",
              "      <td>['biography', 'documentary']</td>\n",
              "      <td>English</td>\n",
              "      <td>['Aviva Kempner']</td>\n",
              "      <td>1h 29m</td>\n",
              "      <td>$1.7M</td>\n",
              "      <td>\"The Life and Times of Hank Greenberg\" is a hu...</td>\n",
              "      <td>80.0</td>\n",
              "      <td>97.0</td>\n",
              "      <td>[\"Dedicated to the millions of Detroit Tigers ...</td>\n",
              "      <td>0.840233</td>\n",
              "      <td>0.697333</td>\n",
              "      <td>0.289333</td>\n",
              "      <td>0.013333</td>\n",
              "      <td>0.223750</td>\n",
              "      <td>0.02430</td>\n",
              "      <td>0.751950</td>\n",
              "      <td>0.574785</td>\n",
              "      <td>0.047392</td>\n",
              "      <td>0.034910</td>\n",
              "      <td>0.917698</td>\n",
              "      <td>It's an adroit manipulation of interviews and ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11</td>\n",
              "      <td>dark_days</td>\n",
              "      <td>Dec 4, 2015</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['documentary']</td>\n",
              "      <td>Marc Singer</td>\n",
              "      <td>['Marc Singer']</td>\n",
              "      <td>1h 34m</td>\n",
              "      <td>$436.8K</td>\n",
              "      <td>\"Dark Days\" is a feature length documentary ab...</td>\n",
              "      <td>89.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>['Equal parts inspiring and depressing. A lite...</td>\n",
              "      <td>0.906725</td>\n",
              "      <td>0.703750</td>\n",
              "      <td>0.221500</td>\n",
              "      <td>0.075000</td>\n",
              "      <td>0.090550</td>\n",
              "      <td>0.10805</td>\n",
              "      <td>0.801450</td>\n",
              "      <td>-0.006655</td>\n",
              "      <td>0.159434</td>\n",
              "      <td>0.424432</td>\n",
              "      <td>0.416135</td>\n",
              "      <td>This is the world discovered and illuminated b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>12</td>\n",
              "      <td>filth_and_the_fury</td>\n",
              "      <td>Mar 29, 2000</td>\n",
              "      <td>R (Strong Language|Sexual Content|Drug Use)</td>\n",
              "      <td>['documentary']</td>\n",
              "      <td>English</td>\n",
              "      <td>['Julien Temple']</td>\n",
              "      <td>1h 48m</td>\n",
              "      <td>$606.6K</td>\n",
              "      <td>Assembled from unseen archive footage, rare of...</td>\n",
              "      <td>88.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>[\"Nevermind the Bollocks Here's the Sex Pistol...</td>\n",
              "      <td>-0.026756</td>\n",
              "      <td>0.745000</td>\n",
              "      <td>0.143222</td>\n",
              "      <td>0.111778</td>\n",
              "      <td>0.034091</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.965909</td>\n",
              "      <td>0.057900</td>\n",
              "      <td>0.130965</td>\n",
              "      <td>0.411622</td>\n",
              "      <td>0.457413</td>\n",
              "      <td>[]Best for older teens, especially Sex Pistols...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>20</td>\n",
              "      <td>wattstax</td>\n",
              "      <td>Feb 18, 2016</td>\n",
              "      <td>R</td>\n",
              "      <td>['music', 'documentary']</td>\n",
              "      <td>English</td>\n",
              "      <td>['Mel Stuart']</td>\n",
              "      <td>1h 38m</td>\n",
              "      <td>NaN</td>\n",
              "      <td>In 1972 at the Los Angeles Coliseum, director ...</td>\n",
              "      <td>90.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>['Black people of america, I Love You', 'Conju...</td>\n",
              "      <td>0.666143</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.181714</td>\n",
              "      <td>0.018286</td>\n",
              "      <td>0.172250</td>\n",
              "      <td>0.03780</td>\n",
              "      <td>0.789950</td>\n",
              "      <td>0.423465</td>\n",
              "      <td>0.097406</td>\n",
              "      <td>0.077102</td>\n",
              "      <td>0.825492</td>\n",
              "      <td>All [the performers] draw lively reactions fro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>35</td>\n",
              "      <td>original_kings_of_comedy</td>\n",
              "      <td>Aug 18, 2000</td>\n",
              "      <td>R (Language and Sex Related Humor)</td>\n",
              "      <td>['comedy', 'documentary']</td>\n",
              "      <td>English</td>\n",
              "      <td>['Spike Lee']</td>\n",
              "      <td>1h 55m</td>\n",
              "      <td>$38.2M</td>\n",
              "      <td>A cultural phenomenon for our time: Spike Lee ...</td>\n",
              "      <td>79.0</td>\n",
              "      <td>83.0</td>\n",
              "      <td>[\"Though an appealing lineup, the capturing do...</td>\n",
              "      <td>0.606740</td>\n",
              "      <td>0.649400</td>\n",
              "      <td>0.300200</td>\n",
              "      <td>0.050400</td>\n",
              "      <td>0.144250</td>\n",
              "      <td>0.05435</td>\n",
              "      <td>0.801400</td>\n",
              "      <td>0.317675</td>\n",
              "      <td>0.155835</td>\n",
              "      <td>0.421047</td>\n",
              "      <td>0.423119</td>\n",
              "      <td>[Spike Lee] knows the show belongs to his come...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Unnamed: 0  ...                                     critic_reviews\n",
              "4            4  ...  It's an adroit manipulation of interviews and ...\n",
              "11          11  ...  This is the world discovered and illuminated b...\n",
              "12          12  ...  []Best for older teens, especially Sex Pistols...\n",
              "20          20  ...  All [the performers] draw lively reactions fro...\n",
              "35          35  ...  [Spike Lee] knows the show belongs to his come...\n",
              "\n",
              "[5 rows x 25 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8a9VVL6dgIr"
      },
      "source": [
        "combined = ' '.join(selected_genre[\"critic_reviews\"])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qcNc4iUdNaj"
      },
      "source": [
        "processed_text = combined.lower()\n",
        "processed_text=processed_text.translate(str.maketrans(\"\", \"\", punctuation))\n",
        "processed_text = re.sub(r'[^\\x00-\\x7f]',r'', processed_text) "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-2O-sagdNak",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "992d1e51-ee94-42ec-ebea-775f52be6c9b"
      },
      "source": [
        "print('corpus length:', len(processed_text))\n",
        "\n",
        "chars = sorted(list(set(processed_text)))\n",
        "print('total chars:', len(chars))\n",
        "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "indices_char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "corpus length: 223041\n",
            "total chars: 37\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAc1UeGMdNak",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a267122e-c4e6-4db3-8487-672982a425c0"
      },
      "source": [
        "# cut the text in semi-redundant sequences of maxlen characters\n",
        "maxlen = 40\n",
        "step = 3\n",
        "sentences = []\n",
        "next_chars = []\n",
        "for i in range(0, len(processed_text) - maxlen, step):\n",
        "    sentences.append(processed_text[i: i + maxlen])\n",
        "    next_chars.append(processed_text[i + maxlen])\n",
        "print('nb sequences:', len(sentences))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nb sequences: 74334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EayTgWzGdNal",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4e88043-3b71-4f5b-f3ba-b99f7e1ac22d"
      },
      "source": [
        "print('Vectorization...')\n",
        "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        x[i, t, char_indices[char]] = 1\n",
        "    y[i, char_indices[next_chars[i]]] = 1"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vectorization...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8QgYr3hdNal",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0acb102f-823b-428b-a2a6-cbead4712ee4"
      },
      "source": [
        "x.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(74334, 40, 37)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JK2F6z4adNal",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e151e352-778f-4213-c7f9-12f38cb5a457"
      },
      "source": [
        "y.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(74334, 37)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4Xa0NE1dNam",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6c04a66-93ea-4de3-ae89-794bdf9baebf"
      },
      "source": [
        "y[0:10]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ True, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False],\n",
              "       [False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False,  True, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False],\n",
              "       [False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False,  True, False, False, False, False, False,\n",
              "        False],\n",
              "       [False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False,  True, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False],\n",
              "       [False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False,  True, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False],\n",
              "       [False, False, False, False, False, False, False, False, False,\n",
              "        False, False,  True, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False],\n",
              "       [ True, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False],\n",
              "       [False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False,  True, False, False, False, False, False, False,\n",
              "        False],\n",
              "       [False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False,  True,\n",
              "        False],\n",
              "       [False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False,  True, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIsYPoOEdNam",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d432e2a-2818-409b-8e1e-993490c5489d"
      },
      "source": [
        "# build the model: a single LSTM\n",
        "print('Build model...')\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
        "model.add(Dense(len(chars), activation='softmax'))\n",
        "\n",
        "#optimizer = RMSprop(lr=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(learning_rate=0.01))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Build model...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAouteZRdNan",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba8b0673-b8ad-4729-ef21-dae2832c886d"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 128)               84992     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 37)                4773      \n",
            "=================================================================\n",
            "Total params: 89,765\n",
            "Trainable params: 89,765\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFL6EAeqdNan"
      },
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWH7HpdodNao"
      },
      "source": [
        "def on_epoch_end(epoch, _):\n",
        "    # Function invoked at end of each epoch. Prints generated text.\n",
        "    print(\"******************************************************\")\n",
        "    print('----- Generating text after Epoch: %d' % epoch)\n",
        "\n",
        "    start_index = random.randint(0, len(processed_text) - maxlen - 1)\n",
        "    for temperature in [0.2, 0.5, 1.0, 1.2]:\n",
        "        print('----- temperature:', temperature)\n",
        "\n",
        "        generated = ''\n",
        "        sentence = processed_text[start_index: start_index + maxlen]\n",
        "        generated += sentence\n",
        "        print('----- Generating with seed: \"' + sentence + '\"')\n",
        "        sys.stdout.write(generated)\n",
        "\n",
        "        for i in range(400):\n",
        "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "            for t, char in enumerate(sentence):\n",
        "                x_pred[0, t, char_indices[char]] = 1.\n",
        "\n",
        "            preds = model.predict(x_pred, verbose=0)[0]\n",
        "            next_index = sample(preds, temperature)\n",
        "            next_char = indices_char[next_index]\n",
        "\n",
        "            generated += next_char\n",
        "            sentence = sentence[1:] + next_char\n",
        "\n",
        "            sys.stdout.write(next_char)\n",
        "            sys.stdout.flush()\n",
        "        print()\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJcdmC_rdNao",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4087675-297b-4990-88eb-d63c7c732937"
      },
      "source": [
        "import logging, os\n",
        "logging.disable(logging.WARNING)\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
        "\n",
        "# Fit the model\n",
        "model.fit(x, y,\n",
        "          batch_size=128,\n",
        "          epochs=50)\n",
        "          #callbacks=[print_callback])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "581/581 [==============================] - 66s 110ms/step - loss: 2.2132\n",
            "Epoch 2/100\n",
            "581/581 [==============================] - 64s 110ms/step - loss: 1.8473\n",
            "Epoch 3/100\n",
            "581/581 [==============================] - 63s 109ms/step - loss: 1.6944\n",
            "Epoch 4/100\n",
            "581/581 [==============================] - 64s 110ms/step - loss: 1.5945\n",
            "Epoch 5/100\n",
            "581/581 [==============================] - 64s 110ms/step - loss: 1.5252\n",
            "Epoch 6/100\n",
            "581/581 [==============================] - 64s 110ms/step - loss: 1.4730\n",
            "Epoch 7/100\n",
            "581/581 [==============================] - 64s 110ms/step - loss: 1.4336\n",
            "Epoch 8/100\n",
            "581/581 [==============================] - 64s 110ms/step - loss: 1.4001\n",
            "Epoch 9/100\n",
            "581/581 [==============================] - 64s 110ms/step - loss: 1.3723\n",
            "Epoch 10/100\n",
            "581/581 [==============================] - 64s 110ms/step - loss: 1.3492\n",
            "Epoch 11/100\n",
            "581/581 [==============================] - 64s 110ms/step - loss: 1.3313\n",
            "Epoch 12/100\n",
            "581/581 [==============================] - 64s 110ms/step - loss: 1.3174\n",
            "Epoch 13/100\n",
            "581/581 [==============================] - 64s 110ms/step - loss: 1.3023\n",
            "Epoch 14/100\n",
            "581/581 [==============================] - 64s 110ms/step - loss: 1.2892\n",
            "Epoch 15/100\n",
            "581/581 [==============================] - 64s 110ms/step - loss: 1.2789\n",
            "Epoch 16/100\n",
            "581/581 [==============================] - 64s 111ms/step - loss: 1.2685\n",
            "Epoch 17/100\n",
            "581/581 [==============================] - 64s 110ms/step - loss: 1.2579\n",
            "Epoch 18/100\n",
            "581/581 [==============================] - 64s 110ms/step - loss: 1.2513\n",
            "Epoch 19/100\n",
            "581/581 [==============================] - 64s 111ms/step - loss: 1.2410\n",
            "Epoch 20/100\n",
            "581/581 [==============================] - 64s 111ms/step - loss: 1.2336\n",
            "Epoch 21/100\n",
            "581/581 [==============================] - 64s 111ms/step - loss: 1.2244\n",
            "Epoch 22/100\n",
            "581/581 [==============================] - 64s 110ms/step - loss: 1.2161\n",
            "Epoch 23/100\n",
            "581/581 [==============================] - 64s 111ms/step - loss: 1.2125\n",
            "Epoch 24/100\n",
            "581/581 [==============================] - 65s 111ms/step - loss: 1.2060\n",
            "Epoch 25/100\n",
            "581/581 [==============================] - 64s 111ms/step - loss: 1.1991\n",
            "Epoch 26/100\n",
            "581/581 [==============================] - 64s 110ms/step - loss: 1.1907\n",
            "Epoch 27/100\n",
            "581/581 [==============================] - 64s 111ms/step - loss: 1.1862\n",
            "Epoch 28/100\n",
            "581/581 [==============================] - 64s 111ms/step - loss: 1.1823\n",
            "Epoch 29/100\n",
            "581/581 [==============================] - 64s 111ms/step - loss: 1.1732\n",
            "Epoch 30/100\n",
            "581/581 [==============================] - 65s 111ms/step - loss: 1.1700\n",
            "Epoch 31/100\n",
            "581/581 [==============================] - 65s 111ms/step - loss: 1.1658\n",
            "Epoch 32/100\n",
            "581/581 [==============================] - 65s 111ms/step - loss: 1.1626\n",
            "Epoch 33/100\n",
            "581/581 [==============================] - 64s 111ms/step - loss: 1.1527\n",
            "Epoch 34/100\n",
            "581/581 [==============================] - 64s 111ms/step - loss: 1.1517\n",
            "Epoch 35/100\n",
            "581/581 [==============================] - 65s 111ms/step - loss: 1.1454\n",
            "Epoch 36/100\n",
            "581/581 [==============================] - 65s 111ms/step - loss: 1.1410\n",
            "Epoch 37/100\n",
            "581/581 [==============================] - 65s 111ms/step - loss: 1.1398\n",
            "Epoch 38/100\n",
            "581/581 [==============================] - 65s 111ms/step - loss: 1.1338\n",
            "Epoch 39/100\n",
            "581/581 [==============================] - 65s 112ms/step - loss: 1.1317\n",
            "Epoch 40/100\n",
            "581/581 [==============================] - 65s 111ms/step - loss: 1.1273\n",
            "Epoch 41/100\n",
            "581/581 [==============================] - 64s 111ms/step - loss: 1.1221\n",
            "Epoch 42/100\n",
            "581/581 [==============================] - 65s 111ms/step - loss: 1.1203\n",
            "Epoch 43/100\n",
            "581/581 [==============================] - 65s 112ms/step - loss: 1.1155\n",
            "Epoch 44/100\n",
            "581/581 [==============================] - 65s 111ms/step - loss: 1.1116\n",
            "Epoch 45/100\n",
            "581/581 [==============================] - 65s 111ms/step - loss: 1.1043\n",
            "Epoch 46/100\n",
            "581/581 [==============================] - 65s 112ms/step - loss: 1.1036\n",
            "Epoch 47/100\n",
            "581/581 [==============================] - 65s 112ms/step - loss: 1.0985\n",
            "Epoch 48/100\n",
            "581/581 [==============================] - 65s 112ms/step - loss: 1.0949\n",
            "Epoch 49/100\n",
            "581/581 [==============================] - 65s 112ms/step - loss: 1.0922\n",
            "Epoch 50/100\n",
            "581/581 [==============================] - 65s 112ms/step - loss: 1.0889\n",
            "Epoch 51/100\n",
            "581/581 [==============================] - 65s 112ms/step - loss: 1.0864\n",
            "Epoch 52/100\n",
            "581/581 [==============================] - 65s 111ms/step - loss: 1.0804\n",
            "Epoch 53/100\n",
            "581/581 [==============================] - 65s 112ms/step - loss: 1.0803\n",
            "Epoch 54/100\n",
            "581/581 [==============================] - 65s 112ms/step - loss: 1.0755\n",
            "Epoch 55/100\n",
            "581/581 [==============================] - 65s 112ms/step - loss: 1.0713\n",
            "Epoch 56/100\n",
            "581/581 [==============================] - 65s 112ms/step - loss: 1.0711\n",
            "Epoch 57/100\n",
            "581/581 [==============================] - 65s 112ms/step - loss: 1.0720\n",
            "Epoch 58/100\n",
            "581/581 [==============================] - 65s 112ms/step - loss: 1.0682\n",
            "Epoch 59/100\n",
            "581/581 [==============================] - 65s 112ms/step - loss: 1.0603\n",
            "Epoch 60/100\n",
            "581/581 [==============================] - 65s 112ms/step - loss: 1.0573\n",
            "Epoch 61/100\n",
            "581/581 [==============================] - 65s 111ms/step - loss: 1.0551\n",
            "Epoch 62/100\n",
            "581/581 [==============================] - 65s 111ms/step - loss: 1.0505\n",
            "Epoch 63/100\n",
            "581/581 [==============================] - 65s 111ms/step - loss: 1.0492\n",
            "Epoch 64/100\n",
            "581/581 [==============================] - 65s 112ms/step - loss: 1.0478\n",
            "Epoch 65/100\n",
            "581/581 [==============================] - 65s 111ms/step - loss: 1.0456\n",
            "Epoch 66/100\n",
            "581/581 [==============================] - 65s 112ms/step - loss: 1.0425\n",
            "Epoch 67/100\n",
            "581/581 [==============================] - 65s 111ms/step - loss: 1.0386\n",
            "Epoch 68/100\n",
            "581/581 [==============================] - 65s 112ms/step - loss: 1.0357\n",
            "Epoch 69/100\n",
            "581/581 [==============================] - 64s 111ms/step - loss: 1.0293\n",
            "Epoch 70/100\n",
            "581/581 [==============================] - 64s 111ms/step - loss: 1.0320\n",
            "Epoch 71/100\n",
            "581/581 [==============================] - 65s 111ms/step - loss: 1.0287\n",
            "Epoch 72/100\n",
            "581/581 [==============================] - 65s 112ms/step - loss: 1.0274\n",
            "Epoch 73/100\n",
            "581/581 [==============================] - 65s 112ms/step - loss: 1.0212\n",
            "Epoch 74/100\n",
            "581/581 [==============================] - 65s 112ms/step - loss: 1.0225\n",
            "Epoch 75/100\n",
            "581/581 [==============================] - 65s 111ms/step - loss: 1.0186\n",
            "Epoch 76/100\n",
            "581/581 [==============================] - 65s 111ms/step - loss: 1.0148\n",
            "Epoch 77/100\n",
            "581/581 [==============================] - 65s 112ms/step - loss: 1.0088\n",
            "Epoch 78/100\n",
            "581/581 [==============================] - 65s 112ms/step - loss: 1.0129\n",
            "Epoch 79/100\n",
            "581/581 [==============================] - 65s 112ms/step - loss: 1.0087\n",
            "Epoch 80/100\n",
            "581/581 [==============================] - 65s 111ms/step - loss: 1.0065\n",
            "Epoch 81/100\n",
            "581/581 [==============================] - 65s 112ms/step - loss: 1.0032\n",
            "Epoch 82/100\n",
            "581/581 [==============================] - 65s 111ms/step - loss: 0.9986\n",
            "Epoch 83/100\n",
            "581/581 [==============================] - 64s 111ms/step - loss: 1.0001\n",
            "Epoch 84/100\n",
            "581/581 [==============================] - 65s 111ms/step - loss: 0.9933\n",
            "Epoch 85/100\n",
            "581/581 [==============================] - 65s 112ms/step - loss: 0.9952\n",
            "Epoch 86/100\n",
            "581/581 [==============================] - 65s 112ms/step - loss: 0.9912\n",
            "Epoch 87/100\n",
            "581/581 [==============================] - 65s 112ms/step - loss: 0.9917\n",
            "Epoch 88/100\n",
            "581/581 [==============================] - 65s 111ms/step - loss: 0.9860\n",
            "Epoch 89/100\n",
            "581/581 [==============================] - 65s 111ms/step - loss: 0.9854\n",
            "Epoch 90/100\n",
            "581/581 [==============================] - 65s 112ms/step - loss: 0.9795\n",
            "Epoch 91/100\n",
            "581/581 [==============================] - 65s 111ms/step - loss: 0.9776\n",
            "Epoch 92/100\n",
            "581/581 [==============================] - 65s 112ms/step - loss: 0.9825\n",
            "Epoch 93/100\n",
            "581/581 [==============================] - 65s 112ms/step - loss: 0.9729\n",
            "Epoch 94/100\n",
            "581/581 [==============================] - 65s 112ms/step - loss: 0.9723\n",
            "Epoch 95/100\n",
            "581/581 [==============================] - 65s 112ms/step - loss: 0.9704\n",
            "Epoch 96/100\n",
            "581/581 [==============================] - 65s 112ms/step - loss: 0.9686\n",
            "Epoch 97/100\n",
            "581/581 [==============================] - 65s 112ms/step - loss: 0.9646\n",
            "Epoch 98/100\n",
            "581/581 [==============================] - 65s 112ms/step - loss: 0.9617\n",
            "Epoch 99/100\n",
            "581/581 [==============================] - 65s 112ms/step - loss: 0.9614\n",
            "Epoch 100/100\n",
            "581/581 [==============================] - 65s 112ms/step - loss: 0.9598\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff01cf8f850>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WGdPviWdNap"
      },
      "source": [
        "path = f\"{genre}.h5\"\n",
        "model.save_weights(path)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28iXO9BhFxjG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9c84e4a-8734-4be3-a987-f631a8363e7c"
      },
      "source": [
        "start_index = random.randint(0, len(processed_text) - maxlen - 1)\n",
        "for temperature in [0.2, 0.5, 1.0, 1.2]:\n",
        "    print('----- temperature:', temperature)\n",
        "\n",
        "    generated = ''\n",
        "    sentence = processed_text[start_index: start_index + maxlen]\n",
        "    generated += sentence\n",
        "    print('----- Generating with seed: \"' + sentence + '\"')\n",
        "    sys.stdout.write(generated)\n",
        "\n",
        "    for i in range(400):\n",
        "        x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "        for t, char in enumerate(sentence):\n",
        "            x_pred[0, t, char_indices[char]] = 1.\n",
        "\n",
        "        preds = model.predict(x_pred, verbose=0)[0]\n",
        "        next_index = sample(preds, temperature)\n",
        "        next_char = indices_char[next_index]\n",
        "\n",
        "        generated += next_char\n",
        "        sentence = sentence[1:] + next_char\n",
        "\n",
        "        sys.stdout.write(next_char)\n",
        "        sys.stdout.flush()\n",
        "    print()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- temperature: 0.2\n",
            "----- Generating with seed: \"ample joys and sorrows and it will intro\"\n",
            "ample joys and sorrows and it will introduzed to the subject who shays with the film is a strong it is a sining to be difference and the film is a strong chardagances its art too strendly the film is a truth is a strengs but it is a strike the soundtroves and the film is a strip and characters and the portrait of the film is a strong its all the way with the film is a strong is a collicial pressive film chrickand in the film is a strong\n",
            "----- temperature: 0.5\n",
            "----- Generating with seed: \"ample joys and sorrows and it will intro\"\n",
            "ample joys and sorrows and it will introming in on the movie is a rousively funny portrait of the confide the film disying the reality of nonceity of a music fores a strong its all the uniquencely briews stunnently heart in the political gues a frespican lays in nothing to entertaining and had a bigk are concerting for the music funny his creat of the sort of a ballet a strend and oldess on the revelors and such a feelgool good film its\n",
            "----- temperature: 1.0\n",
            "----- Generating with seed: \"ample joys and sorrows and it will intro\"\n",
            "ample joys and sorrows and it will introvent nairynd at its most mares where unvasomical the audacstance to get of coirng ed is sat from gillific flormed cite that is out its loe he dadre attention of the sense of accivan by a bally and sedity but youre it unlikely a compelling moting narrative historically twitic menationships most while brills what sylless and selfion in apprecause the movie is consusted searreate in the holland inspe\n",
            "----- temperature: 1.2\n",
            "----- Generating with seed: \"ample joys and sorrows and it will intro\"\n",
            "ample joys and sorrows and it will introge monise ran could lueile  know story shor well ever gaimisaging with the film wint little  diffecting  the woolld blindgent comes jas and crision to conceptive and of it naturallicm has a new from the inethed of the sort of about the fidstodigats buspurrle documentaries to crives this struggest momentout to agering most wealhreads insparthing documentary what we he really rich the road with stub\n"
          ]
        }
      ]
    }
  ]
}